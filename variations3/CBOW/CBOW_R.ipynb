{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "D8OkefRFBD-Y"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding,Dense ,Lambda\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "78VnlB4xL1vm"
   },
   "source": [
    " a. Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "id": "nacDcyRAC1ih"
   },
   "outputs": [],
   "source": [
    "with open(\"./text.txt\",\"r\") as file:\n",
    "    text=file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_ja0wxNDOoZ"
   },
   "source": [
    "Preprocessing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2lx-5javC_OH",
    "outputId": "cc8257eb-3d44-4a8b-cdd7-97596500fbc5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deep learning is a subset of machine learning that focuses on utilizing neural networks to perform tasks such as classification, regression, and representation learning',\n",
       " ' the field takes inspiration from biological neuroscience and is centered around stacking artificial neurons into layers and \"training\" them to process data',\n",
       " ' the adjective \"deep\" refers to the use of multiple layers (ranging from three to several hundred or thousands) in the network',\n",
       " ' methods used can be either supervised, semi-supervised or unsupervised',\n",
       " ' some common deep learning network architectures include fully connected networks, deep belief networks, recurrent neural networks, convolutional neural networks, generative adversarial networks, transformers, and neural radiance fields',\n",
       " ' these architectures have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board gamef programs, where they have produced results comparable to and in some cases surpassing human expert performance',\n",
       " ' early forms of neural networks were inspired by information processing and distributed communication nodes in biological systems, particularly the human brain',\n",
       " ' however, current neural networks do not intend to model the brain function of organisms, and are generally seen as low-quality models for that purpose',\n",
       " '\\n']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences=text.split('.')\n",
    "sentences=[s.lower() for s in sentences]\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mhxMAtyuDWKQ",
    "outputId": "975822ec-899e-4367-b4a1-855d30ca1bdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 7, 10, 27, 28, 8, 11, 7, 12, 29, 30, 31, 4, 1, 3, 32, 33, 34, 13, 35, 36, 2, 37, 7], [5, 38, 39, 40, 14, 15, 41, 2, 10, 42, 43, 44, 45, 46, 47, 16, 2, 48, 49, 3, 50, 51], [5, 52, 6, 53, 3, 5, 54, 8, 55, 16, 56, 14, 57, 3, 58, 59, 17, 60, 9, 5, 18], [61, 62, 63, 64, 65, 19, 66, 19, 17, 67], [20, 68, 6, 7, 18, 21, 69, 70, 71, 1, 6, 72, 1, 73, 4, 1, 74, 4, 1, 75, 76, 1, 77, 2, 4, 78, 22], [79, 21, 23, 80, 81, 3, 22, 82, 83, 84, 85, 86, 87, 88, 24, 11, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 2, 100, 101, 102, 103, 104, 23, 105, 106, 107, 3, 2, 9, 20, 108, 109, 25, 110, 111], [112, 113, 8, 4, 1, 114, 115, 116, 117, 24, 2, 118, 119, 120, 9, 15, 121, 122, 5, 25, 26], [123, 124, 4, 1, 125, 126, 127, 3, 128, 5, 26, 129, 8, 130, 2, 131, 132, 133, 13, 134, 135, 136, 137, 12, 138], []]\n"
     ]
    }
   ],
   "source": [
    "# Tokenizing the sentences\n",
    "tokenizer=Tokenizer()\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "sequences=tokenizer.texts_to_sequences(sentences)\n",
    "print(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rBjbQivTDssO",
    "outputId": "e007f813-d941-4d43-c079-3226a1c9c2b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'networks', 2: 'and', 3: 'to', 4: 'neural', 5: 'the', 6: 'deep', 7: 'learning', 8: 'of', 9: 'in', 10: 'is', 11: 'machine', 12: 'that', 13: 'as', 14: 'from', 15: 'biological', 16: 'layers', 17: 'or', 18: 'network', 19: 'supervised', 20: 'some', 21: 'architectures', 22: 'fields', 23: 'have', 24: 'processing', 25: 'human', 26: 'brain', 27: 'a', 28: 'subset', 29: 'focuses', 30: 'on', 31: 'utilizing', 32: 'perform', 33: 'tasks', 34: 'such', 35: 'classification', 36: 'regression', 37: 'representation', 38: 'field', 39: 'takes', 40: 'inspiration', 41: 'neuroscience', 42: 'centered', 43: 'around', 44: 'stacking', 45: 'artificial', 46: 'neurons', 47: 'into', 48: 'training', 49: 'them', 50: 'process', 51: 'data', 52: 'adjective', 53: 'refers', 54: 'use', 55: 'multiple', 56: 'ranging', 57: 'three', 58: 'several', 59: 'hundred', 60: 'thousands', 61: 'methods', 62: 'used', 63: 'can', 64: 'be', 65: 'either', 66: 'semi', 67: 'unsupervised', 68: 'common', 69: 'include', 70: 'fully', 71: 'connected', 72: 'belief', 73: 'recurrent', 74: 'convolutional', 75: 'generative', 76: 'adversarial', 77: 'transformers', 78: 'radiance', 79: 'these', 80: 'been', 81: 'applied', 82: 'including', 83: 'computer', 84: 'vision', 85: 'speech', 86: 'recognition', 87: 'natural', 88: 'language', 89: 'translation', 90: 'bioinformatics', 91: 'drug', 92: 'design', 93: 'medical', 94: 'image', 95: 'analysis', 96: 'climate', 97: 'science', 98: 'material', 99: 'inspection', 100: 'board', 101: 'gamef', 102: 'programs', 103: 'where', 104: 'they', 105: 'produced', 106: 'results', 107: 'comparable', 108: 'cases', 109: 'surpassing', 110: 'expert', 111: 'performance', 112: 'early', 113: 'forms', 114: 'were', 115: 'inspired', 116: 'by', 117: 'information', 118: 'distributed', 119: 'communication', 120: 'nodes', 121: 'systems', 122: 'particularly', 123: 'however', 124: 'current', 125: 'do', 126: 'not', 127: 'intend', 128: 'model', 129: 'function', 130: 'organisms', 131: 'are', 132: 'generally', 133: 'seen', 134: 'low', 135: 'quality', 136: 'models', 137: 'for', 138: 'purpose'} \n",
      "\n",
      "{'networks': 1, 'and': 2, 'to': 3, 'neural': 4, 'the': 5, 'deep': 6, 'learning': 7, 'of': 8, 'in': 9, 'is': 10, 'machine': 11, 'that': 12, 'as': 13, 'from': 14, 'biological': 15, 'layers': 16, 'or': 17, 'network': 18, 'supervised': 19, 'some': 20, 'architectures': 21, 'fields': 22, 'have': 23, 'processing': 24, 'human': 25, 'brain': 26, 'a': 27, 'subset': 28, 'focuses': 29, 'on': 30, 'utilizing': 31, 'perform': 32, 'tasks': 33, 'such': 34, 'classification': 35, 'regression': 36, 'representation': 37, 'field': 38, 'takes': 39, 'inspiration': 40, 'neuroscience': 41, 'centered': 42, 'around': 43, 'stacking': 44, 'artificial': 45, 'neurons': 46, 'into': 47, 'training': 48, 'them': 49, 'process': 50, 'data': 51, 'adjective': 52, 'refers': 53, 'use': 54, 'multiple': 55, 'ranging': 56, 'three': 57, 'several': 58, 'hundred': 59, 'thousands': 60, 'methods': 61, 'used': 62, 'can': 63, 'be': 64, 'either': 65, 'semi': 66, 'unsupervised': 67, 'common': 68, 'include': 69, 'fully': 70, 'connected': 71, 'belief': 72, 'recurrent': 73, 'convolutional': 74, 'generative': 75, 'adversarial': 76, 'transformers': 77, 'radiance': 78, 'these': 79, 'been': 80, 'applied': 81, 'including': 82, 'computer': 83, 'vision': 84, 'speech': 85, 'recognition': 86, 'natural': 87, 'language': 88, 'translation': 89, 'bioinformatics': 90, 'drug': 91, 'design': 92, 'medical': 93, 'image': 94, 'analysis': 95, 'climate': 96, 'science': 97, 'material': 98, 'inspection': 99, 'board': 100, 'gamef': 101, 'programs': 102, 'where': 103, 'they': 104, 'produced': 105, 'results': 106, 'comparable': 107, 'cases': 108, 'surpassing': 109, 'expert': 110, 'performance': 111, 'early': 112, 'forms': 113, 'were': 114, 'inspired': 115, 'by': 116, 'information': 117, 'distributed': 118, 'communication': 119, 'nodes': 120, 'systems': 121, 'particularly': 122, 'however': 123, 'current': 124, 'do': 125, 'not': 126, 'intend': 127, 'model': 128, 'function': 129, 'organisms': 130, 'are': 131, 'generally': 132, 'seen': 133, 'low': 134, 'quality': 135, 'models': 136, 'for': 137, 'purpose': 138}\n"
     ]
    }
   ],
   "source": [
    "index_to_word=tokenizer.index_word\n",
    "word_to_index=tokenizer.word_index\n",
    "print(index_to_word,\"\\n\")\n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5X9mVL1MEZEt"
   },
   "source": [
    "b. Generate training data ||\n",
    "Creating contexts and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yhtuNz8cEOwA",
    "outputId": "42b9a75f-8d8d-4c98-8aab-1a981c7f54fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 7, 27, 28], [7, 10, 28, 8], [10, 27, 8, 11], [27, 28, 11, 7], [28, 8, 7, 12], [8, 11, 12, 29], [11, 7, 29, 30], [7, 12, 30, 31], [12, 29, 31, 4], [29, 30, 4, 1], [30, 31, 1, 3], [31, 4, 3, 32], [4, 1, 32, 33], [1, 3, 33, 34], [3, 32, 34, 13], [32, 33, 13, 35], [33, 34, 35, 36], [34, 13, 36, 2], [13, 35, 2, 37], [35, 36, 37, 7], [5, 38, 40, 14], [38, 39, 14, 15], [39, 40, 15, 41], [40, 14, 41, 2], [14, 15, 2, 10], [15, 41, 10, 42], [41, 2, 42, 43], [2, 10, 43, 44], [10, 42, 44, 45], [42, 43, 45, 46], [43, 44, 46, 47], [44, 45, 47, 16], [45, 46, 16, 2], [46, 47, 2, 48], [47, 16, 48, 49], [16, 2, 49, 3], [2, 48, 3, 50], [48, 49, 50, 51], [5, 52, 53, 3], [52, 6, 3, 5], [6, 53, 5, 54], [53, 3, 54, 8], [3, 5, 8, 55], [5, 54, 55, 16], [54, 8, 16, 56], [8, 55, 56, 14], [55, 16, 14, 57], [16, 56, 57, 3], [56, 14, 3, 58], [14, 57, 58, 59], [57, 3, 59, 17], [3, 58, 17, 60], [58, 59, 60, 9], [59, 17, 9, 5], [17, 60, 5, 18], [61, 62, 64, 65], [62, 63, 65, 19], [63, 64, 19, 66], [64, 65, 66, 19], [65, 19, 19, 17], [19, 66, 17, 67], [20, 68, 7, 18], [68, 6, 18, 21], [6, 7, 21, 69], [7, 18, 69, 70], [18, 21, 70, 71], [21, 69, 71, 1], [69, 70, 1, 6], [70, 71, 6, 72], [71, 1, 72, 1], [1, 6, 1, 73], [6, 72, 73, 4], [72, 1, 4, 1], [1, 73, 1, 74], [73, 4, 74, 4], [4, 1, 4, 1], [1, 74, 1, 75], [74, 4, 75, 76], [4, 1, 76, 1], [1, 75, 1, 77], [75, 76, 77, 2], [76, 1, 2, 4], [1, 77, 4, 78], [77, 2, 78, 22], [79, 21, 80, 81], [21, 23, 81, 3], [23, 80, 3, 22], [80, 81, 22, 82], [81, 3, 82, 83], [3, 22, 83, 84], [22, 82, 84, 85], [82, 83, 85, 86], [83, 84, 86, 87], [84, 85, 87, 88], [85, 86, 88, 24], [86, 87, 24, 11], [87, 88, 11, 89], [88, 24, 89, 90], [24, 11, 90, 91], [11, 89, 91, 92], [89, 90, 92, 93], [90, 91, 93, 94], [91, 92, 94, 95], [92, 93, 95, 96], [93, 94, 96, 97], [94, 95, 97, 98], [95, 96, 98, 99], [96, 97, 99, 2], [97, 98, 2, 100], [98, 99, 100, 101], [99, 2, 101, 102], [2, 100, 102, 103], [100, 101, 103, 104], [101, 102, 104, 23], [102, 103, 23, 105], [103, 104, 105, 106], [104, 23, 106, 107], [23, 105, 107, 3], [105, 106, 3, 2], [106, 107, 2, 9], [107, 3, 9, 20], [3, 2, 20, 108], [2, 9, 108, 109], [9, 20, 109, 25], [20, 108, 25, 110], [108, 109, 110, 111], [112, 113, 4, 1], [113, 8, 1, 114], [8, 4, 114, 115], [4, 1, 115, 116], [1, 114, 116, 117], [114, 115, 117, 24], [115, 116, 24, 2], [116, 117, 2, 118], [117, 24, 118, 119], [24, 2, 119, 120], [2, 118, 120, 9], [118, 119, 9, 15], [119, 120, 15, 121], [120, 9, 121, 122], [9, 15, 122, 5], [15, 121, 5, 25], [121, 122, 25, 26], [123, 124, 1, 125], [124, 4, 125, 126], [4, 1, 126, 127], [1, 125, 127, 3], [125, 126, 3, 128], [126, 127, 128, 5], [127, 3, 5, 26], [3, 128, 26, 129], [128, 5, 129, 8], [5, 26, 8, 130], [26, 129, 130, 2], [129, 8, 2, 131], [8, 130, 131, 132], [130, 2, 132, 133], [2, 131, 133, 13], [131, 132, 13, 134], [132, 133, 134, 135], [133, 13, 135, 136], [13, 134, 136, 137], [134, 135, 137, 12], [135, 136, 12, 138]] \n",
      "\n",
      "[10, 27, 28, 8, 11, 7, 12, 29, 30, 31, 4, 1, 3, 32, 33, 34, 13, 35, 36, 2, 39, 40, 14, 15, 41, 2, 10, 42, 43, 44, 45, 46, 47, 16, 2, 48, 49, 3, 6, 53, 3, 5, 54, 8, 55, 16, 56, 14, 57, 3, 58, 59, 17, 60, 9, 63, 64, 65, 19, 66, 19, 6, 7, 18, 21, 69, 70, 71, 1, 6, 72, 1, 73, 4, 1, 74, 4, 1, 75, 76, 1, 77, 2, 4, 23, 80, 81, 3, 22, 82, 83, 84, 85, 86, 87, 88, 24, 11, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 2, 100, 101, 102, 103, 104, 23, 105, 106, 107, 3, 2, 9, 20, 108, 109, 25, 8, 4, 1, 114, 115, 116, 117, 24, 2, 118, 119, 120, 9, 15, 121, 122, 5, 4, 1, 125, 126, 127, 3, 128, 5, 26, 129, 8, 130, 2, 131, 132, 133, 13, 134, 135, 136, 137]\n"
     ]
    }
   ],
   "source": [
    "vocab_size=len(word_to_index)+1\n",
    "emb_size=100\n",
    "context_size=2\n",
    "contexts=[]\n",
    "targets=[]\n",
    "for sequence in sequences:\n",
    "  for i in range(context_size,len(sequence)-context_size):\n",
    "    context=[sequence[i-2],sequence[i-1],sequence[i+1],sequence[i+2]]\n",
    "    target=sequence[i]\n",
    "    contexts.append(context)\n",
    "    targets.append(target)\n",
    "\n",
    "print(contexts,\"\\n\")\n",
    "print(targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XTh5gmNKGHSy",
    "outputId": "ba8df7ba-3125-49a9-f326-8326dd454030"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['deep', 'learning', 'a', 'subset'] => is\n",
      "['learning', 'is', 'subset', 'of'] => a\n",
      "['is', 'a', 'of', 'machine'] => subset\n",
      "['a', 'subset', 'machine', 'learning'] => of\n",
      "['subset', 'of', 'learning', 'that'] => machine\n"
     ]
    }
   ],
   "source": [
    "# Printing features with target\n",
    "for i in range(5):\n",
    "  words=[]\n",
    "  target=index_to_word.get(targets[i])\n",
    "  for j in contexts[i]:\n",
    "    words.append(index_to_word.get(j))\n",
    "  print(words,\"=>\",target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lkyi--EgHLi9"
   },
   "source": [
    "Creating training and testing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XTvEgGcjGiC_",
    "outputId": "e9c53578-3a68-41ba-9f16-d262e20df1f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x: (164, 4)\n",
      "Shape of y: (164,)\n"
     ]
    }
   ],
   "source": [
    "x=np.array(contexts)\n",
    "y=np.array(targets)\n",
    "print(\"Shape of x:\", x.shape)\n",
    "print(\"Shape of y:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WSX0c1ydHrsw"
   },
   "source": [
    "c. Train model  || *Defining model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cfq2tA6WHgIk",
    "outputId": "942b1d0c-9b69-462d-ce41-41de17ac4111"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Atharva\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model=Sequential([\n",
    "    Embedding(input_dim=vocab_size,output_dim=emb_size,input_length=context_size*2),\n",
    "    Lambda(lambda x:tf.reduce_mean(x,axis=1)),\n",
    "    Dense(256,activation='relu'),\n",
    "    Dense(512,activation='relu'),\n",
    "    Dense(vocab_size,activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "id": "mnuakkYbIaz4"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aS7-f8tLIiJr",
    "outputId": "d26aae69-c029-4012-98d3-46f0b6955a3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.0117 - loss: 4.9356   \n",
      "Epoch 2/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1009 - loss: 4.9130 \n",
      "Epoch 3/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1098 - loss: 4.8821 \n",
      "Epoch 4/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0918 - loss: 4.8244 \n",
      "Epoch 5/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0610 - loss: 4.7458 \n",
      "Epoch 6/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0807 - loss: 4.5578 \n",
      "Epoch 7/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0699 - loss: 4.4364 \n",
      "Epoch 8/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0858 - loss: 4.2873 \n",
      "Epoch 9/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1204 - loss: 4.1339 \n",
      "Epoch 10/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1174 - loss: 4.0791 \n",
      "Epoch 11/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1436 - loss: 3.8973 \n",
      "Epoch 12/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1462 - loss: 3.6919 \n",
      "Epoch 13/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1793 - loss: 3.4937 \n",
      "Epoch 14/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2001 - loss: 3.4163 \n",
      "Epoch 15/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2390 - loss: 3.1130 \n",
      "Epoch 16/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3127 - loss: 2.8928 \n",
      "Epoch 17/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3003 - loss: 2.7846 \n",
      "Epoch 18/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3837 - loss: 2.4321 \n",
      "Epoch 19/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4319 - loss: 2.1985 \n",
      "Epoch 20/20\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5408 - loss: 1.9197 \n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x,y,epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mxks655_MdoX"
   },
   "source": [
    " d. Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5diZRPqgIl4p",
    "outputId": "996a73ad-c7b2-4fb2-c662-930cb5bd764b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6  7 27 28]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "Context words: ['deep', 'learning', 'a', 'subset']\n",
      "Predicted terget word :  is\n"
     ]
    }
   ],
   "source": [
    "test_words=[index_to_word[index] for index in contexts[0]]\n",
    "\n",
    "input_data=np.expand_dims(contexts[0],axis=0)\n",
    "print(input_data)\n",
    "\n",
    "pred=model.predict(input_data)\n",
    "predicted_index=np.argmax(pred[0])\n",
    "\n",
    "print(\"Context words:\", test_words)\n",
    "print(\"Predicted terget word : \",index_to_word[predicted_index])\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
